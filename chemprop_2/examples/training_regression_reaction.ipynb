{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Regression - Reaction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1014,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/d/workspace/BACKUP-COPY-/chemprop_2/examples\n",
      "/mnt/d/workspace/BACKUP-COPY-/chemprop_2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "current_path=os.getcwd()\n",
    "print(current_path)\n",
    "\n",
    "parent_path=os.path.dirname(current_path)\n",
    "print(parent_path)\n",
    "\n",
    "if parent_path not in sys.path:\n",
    "    sys.path.append(parent_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1015,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from lightning import pytorch as pl\n",
    "from pathlib import Path\n",
    "\n",
    "from chemprop import data, featurizers, models, nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change data inputs here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1016,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "chemprop_dir = Path.cwd().parent\n",
    "num_workers = 0  # number of workers for dataloader. 0 means using main process for data loading\n",
    "# smiles_column = 'AAM'\n",
    "# target_columns = ['lograte']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1017,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_npz_normal = np.load(f'../chemprop/data/RC/directed/barriers_cycloadd/barriers_cycloadd_aam_train_normal.npz', allow_pickle=True)\n",
    "train_v_normal = train_npz_normal['node_attrs']\n",
    "train_e_normal = train_npz_normal['edge_attrs']\n",
    "train_idx_g_normal = train_npz_normal['edge_indices']\n",
    "train_y_normal = train_npz_normal['ys'] \n",
    "\n",
    "val_npz_normal = np.load(f'../chemprop/data/RC/directed/barriers_cycloadd/barriers_cycloadd_aam_val_normal.npz', allow_pickle=True)\n",
    "val_v_normal = val_npz_normal['node_attrs']\n",
    "val_e_normal = val_npz_normal['edge_attrs']\n",
    "val_idx_g_normal = val_npz_normal['edge_indices']\n",
    "val_y_normal = val_npz_normal['ys'] \n",
    "\n",
    "test_npz_normal = np.load(f'../chemprop/data/RC/directed/barriers_cycloadd/barriers_cycloadd_aam_test_normal.npz', allow_pickle=True)\n",
    "test_v_normal = test_npz_normal['node_attrs']\n",
    "test_e_normal = test_npz_normal['edge_attrs']\n",
    "test_idx_g_normal = test_npz_normal['edge_indices']\n",
    "test_y_normal = test_npz_normal['ys'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1018,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_npz_rc = np.load(f'../chemprop/data/RC/directed/barriers_cycloadd/barriers_cycloadd_aam_train_rc.npz', allow_pickle=True)\n",
    "train_v_rc = train_npz_rc['node_attrs']\n",
    "train_e_rc = train_npz_rc['edge_attrs']\n",
    "train_idx_g_rc = train_npz_rc['edge_indices']\n",
    "train_y_rc = train_npz_rc['ys'] \n",
    "\n",
    "val_npz_rc = np.load(f'../chemprop/data/RC/directed/barriers_cycloadd/barriers_cycloadd_aam_val_rc.npz', allow_pickle=True)\n",
    "val_v_rc = val_npz_rc['node_attrs']\n",
    "val_e_rc = val_npz_rc['edge_attrs']\n",
    "val_idx_g_rc = val_npz_rc['edge_indices']\n",
    "val_y_rc = val_npz_rc['ys'] \n",
    "\n",
    "test_npz_rc = np.load(f'../chemprop/data/RC/directed/barriers_cycloadd/barriers_cycloadd_aam_test_rc.npz', allow_pickle=True)\n",
    "test_v_rc = test_npz_rc['node_attrs']\n",
    "test_e_rc = test_npz_rc['edge_attrs']\n",
    "test_idx_g_rc = test_npz_rc['edge_indices']\n",
    "test_y_rc = test_npz_rc['ys'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1019,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_npz_super = np.load(f'../chemprop/data/RC/directed/barriers_cycloadd/barriers_cycloadd_aam_train_super.npz', allow_pickle=True)\n",
    "train_v_super = train_npz_super['node_attrs']\n",
    "train_e_super = train_npz_super['edge_attrs']\n",
    "train_idx_g_super = train_npz_super['edge_indices']\n",
    "train_y_super = train_npz_super['ys'] \n",
    "\n",
    "val_npz_super = np.load(f'../chemprop/data/RC/directed/barriers_cycloadd/barriers_cycloadd_aam_val_super.npz', allow_pickle=True)\n",
    "val_v_super = val_npz_super['node_attrs']\n",
    "val_e_super = val_npz_super['edge_attrs']\n",
    "val_idx_g_super = val_npz_super['edge_indices']\n",
    "val_y_super = val_npz_super['ys'] \n",
    "\n",
    "test_npz_super = np.load(f'../chemprop/data/RC/directed/barriers_cycloadd/barriers_cycloadd_aam_test_super.npz', allow_pickle=True)\n",
    "test_v_super = test_npz_super['node_attrs']\n",
    "test_e_super = test_npz_super['edge_attrs']\n",
    "test_idx_g_super = test_npz_super['edge_indices']\n",
    "test_y_super = test_npz_super['ys'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1020,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_v = np.concatenate((train_v_normal, train_v_rc, train_v_super), axis=0)\n",
    "train_e = np.concatenate((train_e_normal, train_e_rc, train_e_super), axis=0)\n",
    "train_idx_g = np.concatenate((train_idx_g_normal, train_idx_g_rc, train_idx_g_super), axis=0)\n",
    "train_y = np.concatenate((train_y_normal, train_y_rc, train_y_super), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1021,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_v = np.concatenate((val_v_normal, val_v_rc, val_v_super), axis=0)\n",
    "val_e = np.concatenate((val_e_normal, val_e_rc, val_e_super), axis=0)\n",
    "val_idx_g = np.concatenate((val_idx_g_normal, val_idx_g_rc, val_idx_g_super), axis=0)\n",
    "val_y = np.concatenate((val_y_normal, val_y_rc, val_y_super), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1022,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_v = np.concatenate((test_v_normal, test_v_rc, test_v_super), axis=0)\n",
    "test_e = np.concatenate((test_e_normal, test_e_rc, test_e_super), axis=0)\n",
    "test_idx_g = np.concatenate((test_idx_g_normal, test_idx_g_rc, test_idx_g_super), axis=0)\n",
    "test_y = np.concatenate((test_y_normal, test_y_rc, test_y_super), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1023,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12648,) (1581,) (1578,)\n"
     ]
    }
   ],
   "source": [
    "print(train_idx_g.shape, val_y.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform data splitting for training, validation, and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1024,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21.74475479]\n",
      "[[21.74475479]\n",
      " [19.75370979]\n",
      " [17.10799026]\n",
      " ...\n",
      " [18.88179398]\n",
      " [13.98910904]\n",
      " [29.49899864]]\n",
      "[[ 0.07020871]\n",
      " [-0.1344098 ]\n",
      " [-0.40630883]\n",
      " ...\n",
      " [-0.22401607]\n",
      " [-0.7268344 ]\n",
      " [ 0.86710775]]\n",
      "[0.07020871]\n",
      "[[-1.18898438]\n",
      " [-0.89972892]\n",
      " [-0.06001916]\n",
      " ...\n",
      " [-1.47195955]\n",
      " [ 2.61759346]\n",
      " [ 0.32106197]]\n"
     ]
    }
   ],
   "source": [
    "train_dset = data.ReactionDataset(train_v, train_e, train_idx_g, train_y)\n",
    "print(train_dset[0][3])\n",
    "scaler = train_dset.normalize_targets()\n",
    "# print(scaler)\n",
    "print(train_dset[0][3])\n",
    "\n",
    "val_dset = data.ReactionDataset(val_v, val_e, val_idx_g, val_y)\n",
    "val_dset.normalize_targets(scaler)\n",
    "test_dset = data.ReactionDataset(test_v, test_e, test_idx_g, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get ReactionDatasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1025,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge_index: [[ 0  1  1  2  1  3  3  4  3  8  3 20  4  5  5  6  5 19  6  7  8  9  8 13\n",
      "   9 10 10 11 11 12 12 13 14 15 15 16 16 17 16 19 16 26 17 18 19 20 20 21\n",
      "  21 22 21 23 23 24 24 25 25 26]\n",
      " [ 1  0  2  1  3  1  4  3  8  3 20  3  5  4  6  5 19  5  7  6  9  8 13  8\n",
      "  10  9 11 10 12 11 13 12 15 14 16 15 17 16 19 16 26 16 18 17 20 19 21 20\n",
      "  22 21 23 21 24 23 25 24 26 25]]\n",
      "reverse_index: [ 1  0  3  2  5  4  7  6  9  8 11 10 13 12 15 14 17 16 19 18 21 20 23 22\n",
      " 25 24 27 26 29 28 31 30 33 32 35 34 37 36 39 38 41 40 43 42 45 44 47 46\n",
      " 49 48 51 50 53 52 55 54 57 56]\n"
     ]
    }
   ],
   "source": [
    "edge_index=train_dset[1][0][-2]\n",
    "print(f'edge_index: {edge_index}')\n",
    "reverse_index=train_dset[1][0][-1]\n",
    "print(f'reverse_index: {reverse_index}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1026,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 3, 2, 5, 4])"
      ]
     },
     "execution_count": 1026,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.arange(6).reshape(-1,2)[:, ::-1].ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1027,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = data.build_dataloader(train_dset, num_workers=num_workers)\n",
    "val_loader = data.build_dataloader(val_dset, num_workers=num_workers, shuffle=False)\n",
    "test_loader = data.build_dataloader(test_dset, num_workers=num_workers, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change Message-Passing Neural Network (MPNN) inputs here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Message passing\n",
    "\n",
    "Message passing blocks must be given the shape of the featurizer's outputs.\n",
    "\n",
    "Options are `mp = nn.BondMessagePassing()` or `mp = nn.AtomMessagePassing()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1028,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 1028,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_v[0].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1029,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdims = (train_v[0].shape[1],train_e[0].shape[1]) # the dimensions of the featurizer, given as (atom_dims, bond_dims).\n",
    "mp = nn.BondMessagePassing(*fdims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1030,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23 29\n"
     ]
    }
   ],
   "source": [
    "print(*fdims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1031,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClassRegistry {\n",
      "    'mean': <class 'chemprop.nn.agg.MeanAggregation'>,\n",
      "    'sum': <class 'chemprop.nn.agg.SumAggregation'>,\n",
      "    'norm': <class 'chemprop.nn.agg.NormAggregation'>\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(nn.agg.AggregationRegistry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1032,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg = nn.MeanAggregation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed-Forward Network (FFN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1033,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClassRegistry {\n",
      "    'regression': <class 'chemprop.nn.predictors.RegressionFFN'>,\n",
      "    'regression-mve': <class 'chemprop.nn.predictors.MveFFN'>,\n",
      "    'regression-evidential': <class 'chemprop.nn.predictors.EvidentialFFN'>,\n",
      "    'regression-quantile': <class 'chemprop.nn.predictors.QuantileFFN'>,\n",
      "    'classification': <class 'chemprop.nn.predictors.BinaryClassificationFFN'>,\n",
      "    'classification-dirichlet': <class 'chemprop.nn.predictors.BinaryDirichletFFN'>,\n",
      "    'multiclass': <class 'chemprop.nn.predictors.MulticlassClassificationFFN'>,\n",
      "    'multiclass-dirichlet': <class 'chemprop.nn.predictors.MulticlassDirichletFFN'>,\n",
      "    'spectral': <class 'chemprop.nn.predictors.SpectralFFN'>\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(nn.PredictorRegistry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1034,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_transform = nn.UnscaleTransform.from_standard_scaler(scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1035,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffn = nn.RegressionFFN(output_transform=output_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1036,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_norm = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1037,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClassRegistry {\n",
      "    'mse': <class 'chemprop.nn.metrics.MSE'>,\n",
      "    'mae': <class 'chemprop.nn.metrics.MAE'>,\n",
      "    'rmse': <class 'chemprop.nn.metrics.RMSE'>,\n",
      "    'bounded-mse': <class 'chemprop.nn.metrics.BoundedMSE'>,\n",
      "    'bounded-mae': <class 'chemprop.nn.metrics.BoundedMAE'>,\n",
      "    'bounded-rmse': <class 'chemprop.nn.metrics.BoundedRMSE'>,\n",
      "    'r2': <class 'chemprop.nn.metrics.R2Score'>,\n",
      "    'binary-mcc': <class 'chemprop.nn.metrics.BinaryMCCMetric'>,\n",
      "    'multiclass-mcc': <class 'chemprop.nn.metrics.MulticlassMCCMetric'>,\n",
      "    'roc': <class 'chemprop.nn.metrics.BinaryAUROC'>,\n",
      "    'prc': <class 'chemprop.nn.metrics.BinaryAUPRC'>,\n",
      "    'accuracy': <class 'chemprop.nn.metrics.BinaryAccuracy'>,\n",
      "    'f1': <class 'chemprop.nn.metrics.BinaryF1Score'>\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(nn.metrics.MetricRegistry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1038,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list = [nn.metrics.RMSE(), nn.metrics.MAE()] \n",
    "# Only the first metric is used for training and early stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct MPNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1039,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_fa_layer=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1040,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mpnn = models.MPNN_1(mp, agg, ffn, batch_norm, metric_list, use_fa_layer)\n",
    "# mpnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1041,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer = pl.Trainer(\n",
    "#     logger=False,\n",
    "#     enable_checkpointing=True,  # Use `True` if you want to save model checkpoints. The checkpoints will be saved in the `checkpoints` folder.\n",
    "#     enable_progress_bar=True,\n",
    "#     accelerator=\"auto\",\n",
    "#     devices=1,\n",
    "#     max_epochs=100,  # number of epochs to train for\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1042,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.fit(mpnn, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1043,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = trainer.test(mpnn, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1044,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1045,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_jump=3,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1046,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpnn = models.MPNN(mp, agg, ffn, batch_norm, metric_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1047,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mpnn = models.MPNN_Modified(\n",
    "#     message_passing=mp,\n",
    "#     predictor=ffn,        \n",
    "#     k_jump=k_jump,\n",
    "#     metrics=metric_list\n",
    "#     # init_lr=1e-4,\n",
    "#     # max_lr=1e-3,\n",
    "# )\n",
    "\n",
    "# print(\"Kh·ªüi t·∫°o m√¥ h√¨nh th√†nh c√¥ng!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1048,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1049,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üí° Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    logger=False,\n",
    "    enable_checkpointing=True,  # Use `True` if you want to save model checkpoints. The checkpoints will be saved in the `checkpoints` folder.\n",
    "    enable_progress_bar=True,\n",
    "    accelerator=\"auto\",\n",
    "    devices=1,\n",
    "    max_epochs=10,  # number of epochs to train for\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1050,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/chem_new/lib/python3.12/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:658: Checkpoint directory /mnt/d/workspace/BACKUP-COPY-/chemprop_2/examples/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1050]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# trainer = pl.Trainer(\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#     max_epochs=10,\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m#     accelerator=\"auto\", \u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m      6\u001b[39m \u001b[38;5;66;03m#     enable_progress_bar=True,\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmpnn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m results = trainer.test(mpnn, test_loader)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/chem_new/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py:561\u001b[39m, in \u001b[36mTrainer.fit\u001b[39m\u001b[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[39m\n\u001b[32m    559\u001b[39m \u001b[38;5;28mself\u001b[39m.training = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    560\u001b[39m \u001b[38;5;28mself\u001b[39m.should_stop = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m561\u001b[39m \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    562\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[32m    563\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/chem_new/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py:48\u001b[39m, in \u001b[36m_call_and_handle_interrupt\u001b[39m\u001b[34m(trainer, trainer_fn, *args, **kwargs)\u001b[39m\n\u001b[32m     46\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m trainer.strategy.launcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     47\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[32m     51\u001b[39m     _call_teardown_hook(trainer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/chem_new/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py:599\u001b[39m, in \u001b[36mTrainer._fit_impl\u001b[39m\u001b[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[39m\n\u001b[32m    592\u001b[39m     download_model_from_registry(ckpt_path, \u001b[38;5;28mself\u001b[39m)\n\u001b[32m    593\u001b[39m ckpt_path = \u001b[38;5;28mself\u001b[39m._checkpoint_connector._select_ckpt_path(\n\u001b[32m    594\u001b[39m     \u001b[38;5;28mself\u001b[39m.state.fn,\n\u001b[32m    595\u001b[39m     ckpt_path,\n\u001b[32m    596\u001b[39m     model_provided=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    597\u001b[39m     model_connected=\u001b[38;5;28mself\u001b[39m.lightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    598\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m599\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    601\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.state.stopped\n\u001b[32m    602\u001b[39m \u001b[38;5;28mself\u001b[39m.training = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/chem_new/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py:988\u001b[39m, in \u001b[36mTrainer._run\u001b[39m\u001b[34m(self, model, ckpt_path)\u001b[39m\n\u001b[32m    985\u001b[39m \u001b[38;5;28mself\u001b[39m._logger_connector.reset_metrics()\n\u001b[32m    987\u001b[39m \u001b[38;5;66;03m# strategy will configure model and move it to the device\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m988\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstrategy\u001b[49m\u001b[43m.\u001b[49m\u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    990\u001b[39m \u001b[38;5;66;03m# hook\u001b[39;00m\n\u001b[32m    991\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.state.fn == TrainerFn.FITTING:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/chem_new/lib/python3.12/site-packages/lightning/pytorch/strategies/strategy.py:155\u001b[39m, in \u001b[36mStrategy.setup\u001b[39m\u001b[34m(self, trainer)\u001b[39m\n\u001b[32m    152\u001b[39m \u001b[38;5;66;03m# let the precision plugin convert the module here so that this strategy hook can decide the order\u001b[39;00m\n\u001b[32m    153\u001b[39m \u001b[38;5;66;03m# of operations\u001b[39;00m\n\u001b[32m    154\u001b[39m \u001b[38;5;28mself\u001b[39m.model = \u001b[38;5;28mself\u001b[39m.precision_plugin.convert_module(\u001b[38;5;28mself\u001b[39m.model)\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[38;5;28mself\u001b[39m.model = \u001b[38;5;28mself\u001b[39m._setup_model(\u001b[38;5;28mself\u001b[39m.model)\n\u001b[32m    158\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m trainer.state.fn == TrainerFn.FITTING:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/chem_new/lib/python3.12/site-packages/lightning/pytorch/strategies/single_device.py:79\u001b[39m, in \u001b[36mSingleDeviceStrategy.model_to_device\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     76\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmodel_to_device\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     78\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mself.model must be set before self.model.to()\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mroot_device\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/chem_new/lib/python3.12/site-packages/lightning/fabric/utilities/device_dtype_mixin.py:55\u001b[39m, in \u001b[36m_DeviceDtypeModuleMixin.to\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     53\u001b[39m device, dtype = torch._C._nn._parse_to(*args, **kwargs)[:\u001b[32m2\u001b[39m]\n\u001b[32m     54\u001b[39m _update_properties(\u001b[38;5;28mself\u001b[39m, device=device, dtype=dtype)\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/chem_new/lib/python3.12/site-packages/torch/nn/modules/module.py:1355\u001b[39m, in \u001b[36mModule.to\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1352\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1353\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1355\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/chem_new/lib/python3.12/site-packages/torch/nn/modules/module.py:915\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    913\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[32m    914\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children():\n\u001b[32m--> \u001b[39m\u001b[32m915\u001b[39m         \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[32m    918\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[32m    919\u001b[39m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[32m    920\u001b[39m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    925\u001b[39m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[32m    926\u001b[39m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/chem_new/lib/python3.12/site-packages/torch/nn/modules/module.py:915\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    913\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[32m    914\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children():\n\u001b[32m--> \u001b[39m\u001b[32m915\u001b[39m         \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[32m    918\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[32m    919\u001b[39m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[32m    920\u001b[39m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    925\u001b[39m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[32m    926\u001b[39m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/chem_new/lib/python3.12/site-packages/torch/nn/modules/module.py:942\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    938\u001b[39m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[32m    939\u001b[39m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[32m    940\u001b[39m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[32m    941\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     param_applied = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    943\u001b[39m p_should_use_set_data = compute_should_use_set_data(param, param_applied)\n\u001b[32m    945\u001b[39m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/chem_new/lib/python3.12/site-packages/torch/nn/modules/module.py:1341\u001b[39m, in \u001b[36mModule.to.<locals>.convert\u001b[39m\u001b[34m(t)\u001b[39m\n\u001b[32m   1334\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t.dim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[32m4\u001b[39m, \u001b[32m5\u001b[39m):\n\u001b[32m   1335\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m t.to(\n\u001b[32m   1336\u001b[39m             device,\n\u001b[32m   1337\u001b[39m             dtype \u001b[38;5;28;01mif\u001b[39;00m t.is_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t.is_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1338\u001b[39m             non_blocking,\n\u001b[32m   1339\u001b[39m             memory_format=convert_to_format,\n\u001b[32m   1340\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1341\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1342\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1343\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1344\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1345\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1346\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1347\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) == \u001b[33m\"\u001b[39m\u001b[33mCannot copy out of meta tensor; no data!\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[31mRuntimeError\u001b[39m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "# trainer = pl.Trainer(\n",
    "#     max_epochs=10,\n",
    "#     accelerator=\"auto\", \n",
    "#     devices = 1,\n",
    "#     logger=False, # B·∫≠t logging\n",
    "#     enable_progress_bar=True,\n",
    "# )\n",
    "\n",
    "trainer.fit(mpnn, train_loader, val_loader)\n",
    "results = trainer.test(mpnn, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer = pl.Trainer(max_epochs=10, accelerator=\"auto\", logger=True, enable_progress_bar=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ===================================================================\n",
    "# # THAY TH·∫æ TO√ÄN B·ªò PH·∫¶N \"Training and testing\" B·∫∞NG ƒêO·∫†N M√É N√ÄY\n",
    "# # ===================================================================\n",
    "\n",
    "# # --- Thi·∫øt l·∫≠p c√°c tham s·ªë cho Ensemble ---\n",
    "# ENSEMBLE_SIZE = 5\n",
    "# all_test_results = []\n",
    "# output_dir = Path(\"./reaction_ensemble_results\")\n",
    "# output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# print(f\"B·∫Øt ƒë·∫ßu hu·∫•n luy·ªán ensemble v·ªõi k√≠ch th∆∞·ªõc = {ENSEMBLE_SIZE}\")\n",
    "# print(\"-\" * 30)\n",
    "\n",
    "# # --- B·∫Øt ƒë·∫ßu v√≤ng l·∫∑p hu·∫•n luy·ªán Ensemble ---\n",
    "# for i in range(ENSEMBLE_SIZE):\n",
    "#     print(f\"\\n--- ƒêang hu·∫•n luy·ªán m√¥ h√¨nh {i+1}/{ENSEMBLE_SIZE} ---\")\n",
    "    \n",
    "#     # 1. T·∫°o m·ªôt m√¥ h√¨nh MPNN m·ªõi cho m·ªói l·∫ßn l·∫∑p ƒë·ªÉ ƒë·∫£m b·∫£o tr·ªçng s·ªë ƒë∆∞·ª£c kh·ªüi t·∫°o l·∫°i\n",
    "#     mpnn = models.MPNNWithSkip(mp, agg, ffn, batch_norm, metric_list)\n",
    "\n",
    "#     # 2. T·∫°o m·ªôt Trainer m·ªõi, ch·ªâ ƒë·ªãnh n∆°i l∆∞u checkpoint cho t·ª´ng m√¥ h√¨nh\n",
    "#     model_checkpoint_dir = output_dir / f\"model_{i}\"\n",
    "#     checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "#         dirpath=model_checkpoint_dir,\n",
    "#         monitor=\"val_loss\",\n",
    "#         mode=\"min\",\n",
    "#         save_top_k=1,\n",
    "#         filename='best_model'\n",
    "#     )\n",
    "    \n",
    "#     trainer = pl.Trainer(\n",
    "#         logger=False,\n",
    "#         enable_checkpointing=True,\n",
    "#         callbacks=[checkpoint_callback],\n",
    "#         enable_progress_bar=True,\n",
    "#         accelerator=\"auto\",\n",
    "#         devices=1,\n",
    "#         max_epochs=200,\n",
    "#     )\n",
    "    \n",
    "#     # 3. Hu·∫•n luy·ªán m√¥ h√¨nh\n",
    "#     trainer.fit(mpnn, train_loader, val_loader)\n",
    "    \n",
    "#     # 4. Ch·∫°y ki·ªÉm tra (test) tr√™n m√¥ h√¨nh t·ªët nh·∫•t v·ª´a ƒë∆∞·ª£c l∆∞u\n",
    "#     # v√† l∆∞u k·∫øt qu·∫£ c·ªßa l·∫ßn l·∫∑p n√†y\n",
    "#     print(f\"--- ƒêang ki·ªÉm tra m√¥ h√¨nh {i+1} ---\")\n",
    "#     best_model_path = checkpoint_callback.best_model_path\n",
    "#     results = trainer.test(mpnn, test_loader, ckpt_path=best_model_path)\n",
    "#     all_test_results.append(results[0]) # results l√† m·ªôt list, l·∫•y ph·∫ßn t·ª≠ ƒë·∫ßu ti√™n\n",
    "\n",
    "# # --- T·ªïng h·ª£p k·∫øt qu·∫£ ---\n",
    "# print(\"\\n\" + \"=\"*30)\n",
    "# print(\"HU·∫§N LUY·ªÜN ENSEMBLE HO√ÄN T·∫§T!\")\n",
    "# print(\"=\"*30)\n",
    "\n",
    "# # Chuy·ªÉn danh s√°ch k·∫øt qu·∫£ th√†nh DataFrame ƒë·ªÉ d·ªÖ t√≠nh to√°n\n",
    "# results_df = pd.DataFrame(all_test_results)\n",
    "\n",
    "# print(\"\\n--- K·∫øt qu·∫£ ki·ªÉm tra c·ªßa t·ª´ng m√¥ h√¨nh ---\")\n",
    "# print(results_df)\n",
    "\n",
    "# print(\"\\n--- K·∫øt qu·∫£ trung b√¨nh c·ªßa Ensemble ---\")\n",
    "# print(results_df.mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chem_new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
