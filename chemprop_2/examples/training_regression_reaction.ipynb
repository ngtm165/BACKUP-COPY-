{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Regression - Reaction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "current_path=os.getcwd()\n",
    "print(current_path)\n",
    "\n",
    "parent_path=os.path.dirname(current_path)\n",
    "print(parent_path)\n",
    "\n",
    "if parent_path not in sys.path:\n",
    "    sys.path.append(parent_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from lightning import pytorch as pl\n",
    "from pathlib import Path\n",
    "\n",
    "from chemprop import data, featurizers, models, nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change data inputs here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "chemprop_dir = Path.cwd().parent\n",
    "num_workers = 0  # number of workers for dataloader. 0 means using main process for data loading\n",
    "# smiles_column = 'AAM'\n",
    "# target_columns = ['lograte']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_npz_normal = np.load(f'../chemprop/data/RC/directed/barriers_cycloadd/barriers_cycloadd_aam_train_normal.npz', allow_pickle=True)\n",
    "train_v_normal = train_npz_normal['node_attrs']\n",
    "train_e_normal = train_npz_normal['edge_attrs']\n",
    "train_idx_g_normal = train_npz_normal['edge_indices']\n",
    "train_y_normal = train_npz_normal['ys'] \n",
    "\n",
    "val_npz_normal = np.load(f'../chemprop/data/RC/directed/barriers_cycloadd/barriers_cycloadd_aam_val_normal.npz', allow_pickle=True)\n",
    "val_v_normal = val_npz_normal['node_attrs']\n",
    "val_e_normal = val_npz_normal['edge_attrs']\n",
    "val_idx_g_normal = val_npz_normal['edge_indices']\n",
    "val_y_normal = val_npz_normal['ys'] \n",
    "\n",
    "test_npz_normal = np.load(f'../chemprop/data/RC/directed/barriers_cycloadd/barriers_cycloadd_aam_test_normal.npz', allow_pickle=True)\n",
    "test_v_normal = test_npz_normal['node_attrs']\n",
    "test_e_normal = test_npz_normal['edge_attrs']\n",
    "test_idx_g_normal = test_npz_normal['edge_indices']\n",
    "test_y_normal = test_npz_normal['ys'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_npz_rc = np.load(f'../chemprop/data/RC/directed/barriers_cycloadd/barriers_cycloadd_aam_train_rc.npz', allow_pickle=True)\n",
    "train_v_rc = train_npz_rc['node_attrs']\n",
    "train_e_rc = train_npz_rc['edge_attrs']\n",
    "train_idx_g_rc = train_npz_rc['edge_indices']\n",
    "train_y_rc = train_npz_rc['ys'] \n",
    "\n",
    "val_npz_rc = np.load(f'../chemprop/data/RC/directed/barriers_cycloadd/barriers_cycloadd_aam_val_rc.npz', allow_pickle=True)\n",
    "val_v_rc = val_npz_rc['node_attrs']\n",
    "val_e_rc = val_npz_rc['edge_attrs']\n",
    "val_idx_g_rc = val_npz_rc['edge_indices']\n",
    "val_y_rc = val_npz_rc['ys'] \n",
    "\n",
    "test_npz_rc = np.load(f'../chemprop/data/RC/directed/barriers_cycloadd/barriers_cycloadd_aam_test_rc.npz', allow_pickle=True)\n",
    "test_v_rc = test_npz_rc['node_attrs']\n",
    "test_e_rc = test_npz_rc['edge_attrs']\n",
    "test_idx_g_rc = test_npz_rc['edge_indices']\n",
    "test_y_rc = test_npz_rc['ys'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_npz_super = np.load(f'../chemprop/data/RC/directed/barriers_cycloadd/barriers_cycloadd_aam_train_super.npz', allow_pickle=True)\n",
    "train_v_super = train_npz_super['node_attrs']\n",
    "train_e_super = train_npz_super['edge_attrs']\n",
    "train_idx_g_super = train_npz_super['edge_indices']\n",
    "train_y_super = train_npz_super['ys'] \n",
    "\n",
    "val_npz_super = np.load(f'../chemprop/data/RC/directed/barriers_cycloadd/barriers_cycloadd_aam_val_super.npz', allow_pickle=True)\n",
    "val_v_super = val_npz_super['node_attrs']\n",
    "val_e_super = val_npz_super['edge_attrs']\n",
    "val_idx_g_super = val_npz_super['edge_indices']\n",
    "val_y_super = val_npz_super['ys'] \n",
    "\n",
    "test_npz_super = np.load(f'../chemprop/data/RC/directed/barriers_cycloadd/barriers_cycloadd_aam_test_super.npz', allow_pickle=True)\n",
    "test_v_super = test_npz_super['node_attrs']\n",
    "test_e_super = test_npz_super['edge_attrs']\n",
    "test_idx_g_super = test_npz_super['edge_indices']\n",
    "test_y_super = test_npz_super['ys'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_v = np.concatenate((train_v_normal, train_v_rc, train_v_super), axis=0)\n",
    "train_e = np.concatenate((train_e_normal, train_e_rc, train_e_super), axis=0)\n",
    "train_idx_g = np.concatenate((train_idx_g_normal, train_idx_g_rc, train_idx_g_super), axis=0)\n",
    "train_y = np.concatenate((train_y_normal, train_y_rc, train_y_super), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_v = np.concatenate((val_v_normal, val_v_rc, val_v_super), axis=0)\n",
    "val_e = np.concatenate((val_e_normal, val_e_rc, val_e_super), axis=0)\n",
    "val_idx_g = np.concatenate((val_idx_g_normal, val_idx_g_rc, val_idx_g_super), axis=0)\n",
    "val_y = np.concatenate((val_y_normal, val_y_rc, val_y_super), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_v = np.concatenate((test_v_normal, test_v_rc, test_v_super), axis=0)\n",
    "test_e = np.concatenate((test_e_normal, test_e_rc, test_e_super), axis=0)\n",
    "test_idx_g = np.concatenate((test_idx_g_normal, test_idx_g_rc, test_idx_g_super), axis=0)\n",
    "test_y = np.concatenate((test_y_normal, test_y_rc, test_y_super), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_idx_g.shape, val_y.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform data splitting for training, validation, and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dset = data.ReactionDataset(train_v, train_e, train_idx_g, train_y)\n",
    "print(train_dset[0][3])\n",
    "scaler = train_dset.normalize_targets()\n",
    "# print(scaler)\n",
    "print(train_dset[0][3])\n",
    "\n",
    "val_dset = data.ReactionDataset(val_v, val_e, val_idx_g, val_y)\n",
    "val_dset.normalize_targets(scaler)\n",
    "test_dset = data.ReactionDataset(test_v, test_e, test_idx_g, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get ReactionDatasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index=train_dset[1][0][-2]\n",
    "print(f'edge_index: {edge_index}')\n",
    "reverse_index=train_dset[1][0][-1]\n",
    "print(f'reverse_index: {reverse_index}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.arange(6).reshape(-1,2)[:, ::-1].ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = data.build_dataloader(train_dset, num_workers=num_workers)\n",
    "val_loader = data.build_dataloader(val_dset, num_workers=num_workers, shuffle=False)\n",
    "test_loader = data.build_dataloader(test_dset, num_workers=num_workers, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change Message-Passing Neural Network (MPNN) inputs here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Message passing\n",
    "\n",
    "Message passing blocks must be given the shape of the featurizer's outputs.\n",
    "\n",
    "Options are `mp = nn.BondMessagePassing()` or `mp = nn.AtomMessagePassing()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_v[0].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdims = (train_v[0].shape[1],train_e[0].shape[1]) # the dimensions of the featurizer, given as (atom_dims, bond_dims).\n",
    "mp = nn.BondMessagePassing(*fdims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(*fdims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nn.agg.AggregationRegistry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg = nn.MeanAggregation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed-Forward Network (FFN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nn.PredictorRegistry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_transform = nn.UnscaleTransform.from_standard_scaler(scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffn = nn.RegressionFFN(output_transform=output_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_norm = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nn.metrics.MetricRegistry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list = [nn.metrics.RMSE(), nn.metrics.MAE()] \n",
    "# Only the first metric is used for training and early stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct MPNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_fa_layer=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mpnn = models.MPNN_1(mp, agg, ffn, batch_norm, metric_list, use_fa_layer)\n",
    "# mpnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer = pl.Trainer(\n",
    "#     logger=False,\n",
    "#     enable_checkpointing=True,  # Use `True` if you want to save model checkpoints. The checkpoints will be saved in the `checkpoints` folder.\n",
    "#     enable_progress_bar=True,\n",
    "#     accelerator=\"auto\",\n",
    "#     devices=1,\n",
    "#     max_epochs=100,  # number of epochs to train for\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.fit(mpnn, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = trainer.test(mpnn, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.ReactionMPNN(\n",
    "    hidden_dim=128,\n",
    "    edge_dim=32,\n",
    "    k_jump=3,\n",
    "    out_dim=1,\n",
    "    warmup_epochs=2,\n",
    "    init_lr=1e-4,\n",
    "    max_lr=1e-3,\n",
    "    final_lr=1e-4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(\n",
    "    max_epochs=10,\n",
    "    accelerator=\"auto\", # Tự động chọn 'gpu' nếu có, nếu không thì 'cpu'\n",
    "    logger=True, # Bật logging\n",
    "    enable_progress_bar=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ===================================================================\n",
    "# # THAY THẾ TOÀN BỘ PHẦN \"Training and testing\" BẰNG ĐOẠN MÃ NÀY\n",
    "# # ===================================================================\n",
    "\n",
    "# # --- Thiết lập các tham số cho Ensemble ---\n",
    "# ENSEMBLE_SIZE = 5\n",
    "# all_test_results = []\n",
    "# output_dir = Path(\"./reaction_ensemble_results\")\n",
    "# output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# print(f\"Bắt đầu huấn luyện ensemble với kích thước = {ENSEMBLE_SIZE}\")\n",
    "# print(\"-\" * 30)\n",
    "\n",
    "# # --- Bắt đầu vòng lặp huấn luyện Ensemble ---\n",
    "# for i in range(ENSEMBLE_SIZE):\n",
    "#     print(f\"\\n--- Đang huấn luyện mô hình {i+1}/{ENSEMBLE_SIZE} ---\")\n",
    "    \n",
    "#     # 1. Tạo một mô hình MPNN mới cho mỗi lần lặp để đảm bảo trọng số được khởi tạo lại\n",
    "#     mpnn = models.MPNNWithSkip(mp, agg, ffn, batch_norm, metric_list)\n",
    "\n",
    "#     # 2. Tạo một Trainer mới, chỉ định nơi lưu checkpoint cho từng mô hình\n",
    "#     model_checkpoint_dir = output_dir / f\"model_{i}\"\n",
    "#     checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "#         dirpath=model_checkpoint_dir,\n",
    "#         monitor=\"val_loss\",\n",
    "#         mode=\"min\",\n",
    "#         save_top_k=1,\n",
    "#         filename='best_model'\n",
    "#     )\n",
    "    \n",
    "#     trainer = pl.Trainer(\n",
    "#         logger=False,\n",
    "#         enable_checkpointing=True,\n",
    "#         callbacks=[checkpoint_callback],\n",
    "#         enable_progress_bar=True,\n",
    "#         accelerator=\"auto\",\n",
    "#         devices=1,\n",
    "#         max_epochs=200,\n",
    "#     )\n",
    "    \n",
    "#     # 3. Huấn luyện mô hình\n",
    "#     trainer.fit(mpnn, train_loader, val_loader)\n",
    "    \n",
    "#     # 4. Chạy kiểm tra (test) trên mô hình tốt nhất vừa được lưu\n",
    "#     # và lưu kết quả của lần lặp này\n",
    "#     print(f\"--- Đang kiểm tra mô hình {i+1} ---\")\n",
    "#     best_model_path = checkpoint_callback.best_model_path\n",
    "#     results = trainer.test(mpnn, test_loader, ckpt_path=best_model_path)\n",
    "#     all_test_results.append(results[0]) # results là một list, lấy phần tử đầu tiên\n",
    "\n",
    "# # --- Tổng hợp kết quả ---\n",
    "# print(\"\\n\" + \"=\"*30)\n",
    "# print(\"HUẤN LUYỆN ENSEMBLE HOÀN TẤT!\")\n",
    "# print(\"=\"*30)\n",
    "\n",
    "# # Chuyển danh sách kết quả thành DataFrame để dễ tính toán\n",
    "# results_df = pd.DataFrame(all_test_results)\n",
    "\n",
    "# print(\"\\n--- Kết quả kiểm tra của từng mô hình ---\")\n",
    "# print(results_df)\n",
    "\n",
    "# print(\"\\n--- Kết quả trung bình của Ensemble ---\")\n",
    "# print(results_df.mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chemprop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
